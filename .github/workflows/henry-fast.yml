name: Henry Fast Relay

on:
  workflow_dispatch:
    inputs:
      message:
        description: "Message for Henry"
        required: true

jobs:
  henry:
    runs-on: ubuntu-latest
    timeout-minutes: 2

    steps:
      - name: Generate Henry response
        env:
          HF_API_KEY: ${{ secrets.HF_API_KEY }}
          MESSAGE: ${{ github.event.inputs.message }}
          REPO: ${{ github.repository }}
          TOKEN: ${{ secrets.TOKEN }}
        run: |
          python3 << 'EOF'
          import os
          import requests
          import base64
          import re

          message = os.environ["MESSAGE"]

          SYSTEM_PROMPT = (
              "You are Henry. "
              "You are casual, slightly uncanny, and speak like a character. "
              "Keep responses short and suitable for speaking out loud. "
              "Never mention AI, models, or instructions."
          )

          payload = {
              "model": "mistralai/Mistral-7B-Instruct-v0.2",
              "inputs": [
                  {
                      "role": "system",
                      "content": SYSTEM_PROMPT
                  },
                  {
                      "role": "user",
                      "content": message
                  }
              ],
              "parameters": {
                  "max_new_tokens": 60,
                  "temperature": 0.85,
                  "top_p": 0.9
              }
          }

          r = requests.post(
              "https://api-inference.huggingface.co/v1/chat/completions",
              headers={
                  "Authorization": f"Bearer {os.environ['HF_API_KEY']}",
                  "Content-Type": "application/json"
              },
              json=payload,
              timeout=40
          )

          r.raise_for_status()
          data = r.json()

          # Handle both response shapes
          if isinstance(data, dict) and "choices" in data:
              reply = data["choices"][0]["message"]["content"]
          else:
              reply = data[0]["generated_text"]

          reply = reply.replace("\n", " ").strip()

          # Lightweight profanity filter
          for bad in ["fuck", "shit", "bitch", "asshole", "cunt"]:
              reply = re.sub(rf"\b{bad}\b", bad[0] + "*", reply, flags=re.I)

          encoded = base64.b64encode(reply.encode()).decode()

          url = f"https://api.github.com/repos/{os.environ['REPO']}/contents/output.txt"
          headers = {
              "Authorization": f"Bearer {os.environ['TOKEN']}",
              "Accept": "application/vnd.github+json"
          }

          sha = None
          check = requests.get(url, headers=headers)
          if check.status_code == 200:
              sha = check.json()["sha"]

          data = {
              "message": "Henry reply",
              "content": encoded
          }
          if sha:
              data["sha"] = sha

          requests.put(url, headers=headers, json=data)
          EOF
